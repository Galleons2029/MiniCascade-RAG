# -*- coding: utf-8 -*-
"""
LangSmith é›†æˆæµ‹è¯• - Intent Agent ç›‘æ§å’Œè°ƒè¯•

è¿™ä¸ªæ–‡ä»¶ä¸“é—¨ç”¨äºæµ‹è¯• Intent Agent å¹¶é€šè¿‡ LangSmith è¿›è¡Œç›‘æ§å’Œè°ƒè¯•ã€‚
è¿è¡Œå‰è¯·ç¡®ä¿è®¾ç½®äº† LangSmith ç¯å¢ƒå˜é‡ã€‚
"""

import os
import pytest
import asyncio
from datetime import datetime

# LangSmith ç›¸å…³å¯¼å…¥
from langsmith import Client
from langchain_openai import ChatOpenAI

from app.core.agent.graph.intent_agent import build_unified_agent_graph


class LangSmithTestRunner:
    """LangSmith æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self):
        self.client = None
        self.setup_langsmith()

    def setup_langsmith(self):
        """è®¾ç½® LangSmith å®¢æˆ·ç«¯"""
        try:
            # æ£€æŸ¥ç¯å¢ƒå˜é‡
            if not os.getenv("LANGCHAIN_API_KEY"):
                print("âš ï¸  LANGCHAIN_API_KEY æœªè®¾ç½®ï¼Œå°†è·³è¿‡ LangSmith é›†æˆ")
                return

            # è®¾ç½® LangSmith ç¯å¢ƒå˜é‡
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            os.environ["LANGCHAIN_PROJECT"] = "MiniCascade-RAG-Intent-Testing"

            # è·å–é¡¹ç›®ä¿¡æ¯ç”¨äºç”Ÿæˆæ­£ç¡®çš„ URL
            self.project_name = "MiniCascade-RAG-Intent-Testing"

            self.client = Client()
            print("âœ… LangSmith å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            print(f"âŒ LangSmith åˆå§‹åŒ–å¤±è´¥: {e}")

    def create_test_llm(self):
        """åˆ›å»ºç”¨äºæµ‹è¯•çš„ LLM"""
        api_key = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("éœ€è¦è®¾ç½® LLM_API_KEY æˆ– OPENAI_API_KEY")

        # ä½¿ç”¨ LangSmith åŒ…è£…çš„ LLM
        llm = ChatOpenAI(
            model=os.getenv("LLM_MODEL", "gpt-3.5-turbo"),
            temperature=0.1,
            api_key=api_key,
            base_url=os.getenv("LLM_BASE_URL"),  # æ”¯æŒè‡ªå®šä¹‰ base_url
        )

        return llm

    async def run_intent_test_suite(self):
        """è¿è¡Œå®Œæ•´çš„æ„å›¾æµ‹è¯•å¥—ä»¶"""
        if not self.client:
            print("âš ï¸  LangSmith æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")
            return

        llm = self.create_test_llm()
        graph = build_unified_agent_graph(llm)

        # æµ‹è¯•ç”¨ä¾‹
        test_cases = [
            {"name": "QA_Intent_Simple", "message": "ä»€ä¹ˆæ˜¯RAGç³»ç»Ÿï¼Ÿ", "expected_intent": "qa"},
            {"name": "QA_Intent_Complex", "message": "ä¸Šå‘¨çš„é”€å”®æ•°æ®æ˜¾ç¤ºäº†ä»€ä¹ˆè¶‹åŠ¿ï¼Ÿ", "expected_intent": "qa"},
            {"name": "Write_Intent", "message": "è¯·å¸®æˆ‘å†™ä¸€ä»½å…³äºAIå‘å±•çš„æŠ¥å‘Š", "expected_intent": "write"},
            {"name": "Search_Intent", "message": "æœç´¢æœ€æ–°çš„æœºå™¨å­¦ä¹ è®ºæ–‡", "expected_intent": "search"},
            {"name": "Exec_Intent", "message": "æ‰§è¡Œæ•°æ®å¤‡ä»½ä»»åŠ¡", "expected_intent": "exec"},
            {"name": "Smalltalk_Intent", "message": "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "expected_intent": "smalltalk"},
            {
                "name": "Multi_Turn_Context",
                "messages": [
                    {"role": "user", "content": "è¿™ä¸ªæœˆçš„é”€å”®é¢æ˜¯å¤šå°‘ï¼Ÿ"},
                    {"role": "assistant", "content": "è¿™ä¸ªæœˆçš„é”€å”®é¢æ˜¯100ä¸‡å…ƒ"},
                    {"role": "user", "content": "ä¸Šä¸ªæœˆçš„å‘¢ï¼Ÿ"},
                ],
                "expected_intent": "qa",
            },
        ]

        results = []

        for test_case in test_cases:
            print(f"ğŸ§ª è¿è¡Œæµ‹è¯•: {test_case['name']}")

            try:
                # å‡†å¤‡è¾“å…¥
                if "messages" in test_case:
                    messages = test_case["messages"]
                else:
                    messages = [{"role": "user", "content": test_case["message"]}]

                # è¿è¡Œæµ‹è¯•ï¼ˆä¼šè‡ªåŠ¨è®°å½•åˆ° LangSmithï¼‰
                # ç”Ÿæˆç¬¦åˆéªŒè¯è§„åˆ™çš„ session_idï¼ˆåªåŒ…å«å­—æ¯æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦ï¼‰
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ç§»é™¤å¾®ç§’çš„å3ä½
                session_id = f"test-{test_case['name']}-{timestamp}"

                result = await graph.ainvoke({"messages": messages, "session_id": session_id})

                # éªŒè¯ç»“æœ
                actual_intent = result.get("intent", "unknown")
                expected_intent = test_case["expected_intent"]

                test_result = {
                    "test_name": test_case["name"],
                    "expected_intent": expected_intent,
                    "actual_intent": actual_intent,
                    "confidence": result.get("intent_confidence", 0),
                    "success": actual_intent == expected_intent,
                    "full_result": result,
                }

                results.append(test_result)

                status = "âœ…" if test_result["success"] else "âŒ"
                print(f"{status} {test_case['name']}: {actual_intent} (ç½®ä¿¡åº¦: {test_result['confidence']:.2f})")

            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥ {test_case['name']}: {e}")
                results.append({"test_name": test_case["name"], "error": str(e), "success": False})

        return results

    def generate_test_report(self, results):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        total_tests = len(results)
        successful_tests = sum(1 for r in results if r.get("success", False))

        print("\n" + "=" * 60)
        print("ğŸ“Š Intent Agent æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"æˆåŠŸ: {successful_tests}")
        print(f"å¤±è´¥: {total_tests - successful_tests}")
        print(f"æˆåŠŸç‡: {successful_tests / total_tests * 100:.1f}%")

        print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for result in results:
            if result.get("success"):
                print(f"âœ… {result['test_name']}: {result['actual_intent']} (ç½®ä¿¡åº¦: {result.get('confidence', 0):.2f})")
            else:
                expected = result.get("expected_intent")
                actual = result.get("actual_intent")
                error_msg = result.get("error", f"é¢„æœŸ: {expected}, å®é™…: {actual}")
                print(f"âŒ {result['test_name']}: {error_msg}")

        if self.client:
            try:
                # è·å–æ­£ç¡®çš„é¡¹ç›® URL
                project_id = self.project_name.replace("-", "_").lower()
                project_url = f"https://smith.langchain.com/o/default/projects/p/{project_id}"
                print(f"\nğŸ”— æŸ¥çœ‹è¯¦ç»†è¿½è¸ª: {project_url}")
                print("ğŸ’¡ å¦‚æœé“¾æ¥æ— æ³•è®¿é—®ï¼Œè¯·ç›´æ¥è®¿é—® https://smith.langchain.com/ å¹¶æŸ¥æ‰¾é¡¹ç›®")
            except Exception:
                print("\nğŸ”— æŸ¥çœ‹è¯¦ç»†è¿½è¸ª: https://smith.langchain.com/")
                print("ğŸ’¡ è¯·åœ¨ LangSmith Dashboard ä¸­æŸ¥æ‰¾é¡¹ç›®: MiniCascade-RAG-Intent-Testing")


@pytest.mark.asyncio
async def test_intent_agent_with_langsmith():
    """ä½¿ç”¨ LangSmith æµ‹è¯• Intent Agent"""
    runner = LangSmithTestRunner()

    if not runner.client:
        pytest.skip("LangSmith æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")

    results = await runner.run_intent_test_suite()
    runner.generate_test_report(results)

    # æ–­è¨€è‡³å°‘æœ‰ä¸€äº›æµ‹è¯•æˆåŠŸ
    successful_tests = sum(1 for r in results if r.get("success", False))
    assert successful_tests > 0, "è‡³å°‘åº”è¯¥æœ‰ä¸€ä¸ªæµ‹è¯•æˆåŠŸ"


@pytest.mark.asyncio
async def test_rag_pipeline_tracing():
    """æµ‹è¯•å®Œæ•´ RAG æµç¨‹çš„è¿½è¸ª"""
    runner = LangSmithTestRunner()

    if not runner.client:
        pytest.skip("LangSmith æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")

    llm = runner.create_test_llm()

    # Mock VectorRetriever for testing
    from unittest.mock import patch, MagicMock

    with patch("app.core.agent.graph.intent_agent.VectorRetriever") as mock_retriever_class:
        mock_retriever = MagicMock()
        mock_retriever.multi_query.return_value = ["æ‰©å±•æŸ¥è¯¢1", "æ‰©å±•æŸ¥è¯¢2", "æ‰©å±•æŸ¥è¯¢3"]
        mock_retriever.retrieve_top_k.return_value = ["æ–‡æ¡£ç‰‡æ®µ1", "æ–‡æ¡£ç‰‡æ®µ2"]
        mock_retriever.rerank.return_value = ["é‡æ’åç‰‡æ®µ1", "é‡æ’åç‰‡æ®µ2"]
        mock_retriever_class.return_value = mock_retriever

        graph = build_unified_agent_graph(llm)

        # è¿è¡Œå®Œæ•´çš„ RAG æµç¨‹
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        result = await graph.ainvoke(
            {
                "messages": [{"role": "user", "content": "ä¸Šå‘¨çš„é”€å”®æ•°æ®åˆ†ææŠ¥å‘Š"}],
                "session_id": f"rag-pipeline-test-{timestamp}",
            }
        )

        # éªŒè¯ RAG æµç¨‹çš„å„ä¸ªæ­¥éª¤
        assert "intent" in result
        assert "entities" in result
        assert "context_frame" in result
        assert "rewritten_query" in result
        assert "context_docs" in result

        print("âœ… RAG æµç¨‹è¿½è¸ªæµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    """ç›´æ¥è¿è¡Œæµ‹è¯•"""

    async def main():
        runner = LangSmithTestRunner()
        results = await runner.run_intent_test_suite()
        runner.generate_test_report(results)

    asyncio.run(main())
