#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•æ„å›¾åˆ†ç±»åŠŸèƒ½

è¿™ä¸ªè„šæœ¬ç”¨äºå•ç‹¬æµ‹è¯•å’Œè°ƒè¯•æ„å›¾åˆ†ç±»åŠŸèƒ½ï¼Œå¸®åŠ©ç†è§£ä¸ºä»€ä¹ˆæ‰€æœ‰æµ‹è¯•éƒ½è¿”å› 'other'ã€‚
"""

import os
import sys
import asyncio
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

from langchain_openai import ChatOpenAI


async def test_intent_classification():
    """æµ‹è¯•æ„å›¾åˆ†ç±»åŠŸèƒ½"""
    
    # åˆå§‹åŒ– LLM
    api_key = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ éœ€è¦è®¾ç½® LLM_API_KEY æˆ– OPENAI_API_KEY")
        return
    
    llm = ChatOpenAI(
        model=os.getenv("LLM_MODEL", "gpt-3.5-turbo"),
        temperature=0.1,
        api_key=api_key,
        base_url=os.getenv("LLM_BASE_URL")
    )
    
    print("ğŸ¤– æµ‹è¯•æ„å›¾åˆ†ç±»åŠŸèƒ½")
    print("=" * 50)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_messages = [
        "ä»€ä¹ˆæ˜¯RAGç³»ç»Ÿï¼Ÿ",
        "ä¸Šå‘¨çš„é”€å”®æ•°æ®æ˜¾ç¤ºäº†ä»€ä¹ˆè¶‹åŠ¿ï¼Ÿ", 
        "è¯·å¸®æˆ‘å†™ä¸€ä»½å…³äºAIå‘å±•çš„æŠ¥å‘Š",
        "æœç´¢æœ€æ–°çš„æœºå™¨å­¦ä¹ è®ºæ–‡",
        "æ‰§è¡Œæ•°æ®å¤‡ä»½ä»»åŠ¡",
        "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
    ]
    
    expected_intents = ["qa", "qa", "write", "search", "exec", "smalltalk"]
    
    for i, message in enumerate(test_messages):
        print(f"\nğŸ§ª æµ‹è¯• {i+1}: {message}")
        print(f"   é¢„æœŸæ„å›¾: {expected_intents[i]}")
        
        # æ„å»ºæç¤ºè¯
        system = (
            "You are an intent classifier. Classify the user's latest message into one of: "
            "qa, write, search, exec, smalltalk, other. "
            "Return a JSON object with keys: intent, confidence (0-1)."
        )
        user = f"Message: {message}\nRespond with JSON only."
        
        try:
            # è°ƒç”¨ LLM
            resp = await llm.ainvoke([
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ])
            
            # è·å–å“åº”å†…å®¹
            content = getattr(resp, "content", "") or ""
            print(f"   LLM åŸå§‹å“åº”: {content}")
            
            # è§£æ JSON
            try:
                data = json.loads(content) if isinstance(content, str) else {}
                detected_intent = str(data.get("intent", "other"))
                confidence = float(data.get("confidence", 0.5))
                
                print(f"   è§£æç»“æœ: intent={detected_intent}, confidence={confidence}")
                
                # éªŒè¯ç»“æœ
                if detected_intent == expected_intents[i]:
                    print("   âœ… åˆ†ç±»æ­£ç¡®")
                else:
                    print(f"   âŒ åˆ†ç±»é”™è¯¯ (é¢„æœŸ: {expected_intents[i]}, å®é™…: {detected_intent})")
                    
            except json.JSONDecodeError as e:
                print(f"   âŒ JSON è§£æå¤±è´¥: {e}")
                
                # å°è¯•å¤‡ç”¨è§£ææ–¹æ³•
                lc = content.lower() if isinstance(content, str) else ""
                detected_intent = "other"
                for k in ["qa", "write", "search", "exec", "smalltalk"]:
                    if k in lc:
                        detected_intent = k
                        break
                
                print(f"   å¤‡ç”¨è§£æç»“æœ: {detected_intent}")
                
        except Exception as e:
            print(f"   âŒ LLM è°ƒç”¨å¤±è´¥: {e}")


async def test_improved_prompts():
    """æµ‹è¯•æ”¹è¿›çš„æç¤ºè¯"""
    
    # åˆå§‹åŒ– LLM
    api_key = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ éœ€è¦è®¾ç½® LLM_API_KEY æˆ– OPENAI_API_KEY")
        return
    
    llm = ChatOpenAI(
        model=os.getenv("LLM_MODEL", "gpt-3.5-turbo"),
        temperature=0.1,
        api_key=api_key,
        base_url=os.getenv("LLM_BASE_URL")
    )
    
    print("\n" + "=" * 50)
    print("ğŸš€ æµ‹è¯•æ”¹è¿›çš„æç¤ºè¯")
    print("=" * 50)
    
    # æ”¹è¿›çš„æç¤ºè¯
    improved_system = """ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†ç±»å™¨ã€‚è¯·å°†ç”¨æˆ·çš„æ¶ˆæ¯åˆ†ç±»åˆ°ä»¥ä¸‹ç±»åˆ«ä¹‹ä¸€ï¼š

1. qa - é—®ç­”ç±»ï¼šç”¨æˆ·è¯¢é—®é—®é¢˜ï¼Œéœ€è¦è·å–ä¿¡æ¯æˆ–è§£é‡Š
2. write - å†™ä½œç±»ï¼šç”¨æˆ·è¦æ±‚å†™ä½œã€æ€»ç»“ã€åˆ›ä½œå†…å®¹
3. search - æœç´¢ç±»ï¼šç”¨æˆ·è¦æ±‚æœç´¢ã€æŸ¥æ‰¾ç‰¹å®šä¿¡æ¯
4. exec - æ‰§è¡Œç±»ï¼šç”¨æˆ·è¦æ±‚æ‰§è¡Œç‰¹å®šä»»åŠ¡æˆ–æ“ä½œ
5. smalltalk - é—²èŠç±»ï¼šæ—¥å¸¸å¯¹è¯ã€é—®å€™ã€é—²èŠ
6. other - å…¶ä»–ï¼šä¸å±äºä»¥ä¸Šä»»ä½•ç±»åˆ«

è¯·è¿”å›JSONæ ¼å¼ï¼š{"intent": "åˆ†ç±»ç»“æœ", "confidence": ç½®ä¿¡åº¦(0-1ä¹‹é—´çš„æ•°å­—)}

ç¤ºä¾‹ï¼š
- "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ" â†’ {"intent": "qa", "confidence": 0.9}
- "å¸®æˆ‘å†™ä¸€ä»½æŠ¥å‘Š" â†’ {"intent": "write", "confidence": 0.9}
- "æœç´¢æœ€æ–°æ–°é—»" â†’ {"intent": "search", "confidence": 0.9}"""
    
    test_messages = [
        "ä»€ä¹ˆæ˜¯RAGç³»ç»Ÿï¼Ÿ",
        "è¯·å¸®æˆ‘å†™ä¸€ä»½å…³äºAIå‘å±•çš„æŠ¥å‘Š", 
        "æœç´¢æœ€æ–°çš„æœºå™¨å­¦ä¹ è®ºæ–‡",
        "ä½ å¥½"
    ]
    
    for message in test_messages:
        print(f"\nğŸ§ª æµ‹è¯•æ¶ˆæ¯: {message}")
        
        try:
            resp = await llm.ainvoke([
                {"role": "system", "content": improved_system},
                {"role": "user", "content": message},
            ])
            
            content = getattr(resp, "content", "") or ""
            print(f"   LLM å“åº”: {content}")
            
            # è§£æç»“æœ
            try:
                data = json.loads(content)
                print(f"   âœ… è§£ææˆåŠŸ: {data}")
            except:
                print(f"   âŒ JSON è§£æå¤±è´¥")
                
        except Exception as e:
            print(f"   âŒ è°ƒç”¨å¤±è´¥: {e}")


if __name__ == "__main__":
    async def main():
        await test_intent_classification()
        await test_improved_prompts()
    
    asyncio.run(main())
